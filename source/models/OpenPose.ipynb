{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import math\n",
    "import cv2\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.modules.conv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL 2\n",
    "\n",
    "class OpenPose_first_and_second_Part_of_InitialStage(nn.Module):\n",
    "    def __init__(self, num_channels=128):\n",
    "        super().__init__()\n",
    "        self.num_channels=num_channels\n",
    "        self.model = nn.Sequential(\n",
    "            conv(3,  32, stride=2, bias=False),\n",
    "            conv_dw( 32,  64),\n",
    "            conv_dw( 64, 128, stride=2),\n",
    "            conv_dw(128, 128),\n",
    "            conv_dw(128, 256, stride=2),\n",
    "            conv_dw(256, 256),\n",
    "            conv_dw(256, 512),  # conv4_2\n",
    "            conv_dw(512, 512, dilation=2, padding=2),\n",
    "            conv_dw(512, 512),\n",
    "            conv_dw(512, 512),\n",
    "            conv_dw(512, 512),\n",
    "            conv_dw(512, 512)   # conv5_5\n",
    "         )\n",
    "        # self.cpm = Cpm(256, num_channels)\n",
    "        # self.initial_stage = InitialStage(num_channels)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        backbone_features = self.model(x)\n",
    "        # backbone_features = self.cpm(backbone_features)\n",
    "        # stages_output = self.initial_stage(backbone_features)\n",
    "        return backbone_features\n",
    "\n",
    "class Baseline_2(nn.Module):\n",
    "\n",
    "    def __init__(self,inference_model,freeze=False,OUTPUT_SIZE=(32,57)):\n",
    "        super().__init__()\n",
    "        self.name = \"baseline2_freeze\" if freeze else \"baseline2_NoFreeze\"\n",
    "        self.num_channels = inference_model.num_channels\n",
    "        self.OUTPUT_SIZE = OUTPUT_SIZE\n",
    "        self.inference_model = inference_model\n",
    "        \n",
    "        if freeze:\n",
    "            for param in inference_model.parameters():\n",
    "                param.requires_grad = False\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=64, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=64,out_channels=32,kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=32,out_channels=1,kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d(output_size=OUTPUT_SIZE)\n",
    "        )\n",
    "        self.last = nn.Sequential(\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=OUTPUT_SIZE[0]*OUTPUT_SIZE[1],out_features=256),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=256,out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=128,out_features=32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=32,out_features=2)\n",
    "        )    \n",
    "\n",
    "    def forward(self, x):\n",
    "        inference_output = self.inference_model(x)\n",
    "        \n",
    "        base_output = self.base(inference_output)\n",
    "        last_out = self.last(base_output)\n",
    "        return last_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_state(net, checkpoint):\n",
    "    source_state = checkpoint['state_dict']\n",
    "    target_state = net.state_dict()\n",
    "    new_target_state = collections.OrderedDict()\n",
    "    for target_key, target_value in target_state.items():\n",
    "        if target_key in source_state and source_state[target_key].size() == target_state[target_key].size():\n",
    "            new_target_state[target_key] = source_state[target_key]\n",
    "        else:\n",
    "            new_target_state[target_key] = target_state[target_key]\n",
    "            print('[WARNING] Not found pre-trained parameters for {}'.format(target_key))\n",
    "\n",
    "    net.load_state_dict(new_target_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(freeze=True):\n",
    "    model = OpenPose_first_and_second_Part_of_InitialStage()\n",
    "    load_state(model, checkpoint)\n",
    "    model = Baseline_2(model,freeze=True)\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
